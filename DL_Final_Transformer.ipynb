{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Final Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuinnStraus/CSCI-1470-final/blob/main/DL_Final_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypianoroll"
      ],
      "metadata": {
        "id": "ahIhNfAXm0nT",
        "outputId": "18bb8ac7-0b28-4dd3-8a2a-f8f086eeaf83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypianoroll in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.4.1)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (0.2.9)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (0.11.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT0_TItcESTP"
      },
      "source": [
        "import pypianoroll\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Fi86GSEMgb",
        "outputId": "5b5cd01f-a044-4b1b-bd2d-d5fb0ec03dfb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8w98EgLLUV"
      },
      "source": [
        "STOP_TOKEN = '<stop>'\n",
        "PAD_TOKEN = '<pad>'\n",
        "\n",
        "\n",
        "CHUNK_SZ = 1000\n",
        "WINDOW_SZ = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8-DOLEAEdod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0af529-5c78-4bd2-e2d6-a1d940485166"
      },
      "source": [
        "# Convert Text to array\n",
        "\n",
        "text = []\n",
        "root_dir = 'gdrive/Shared drives/CSCI1470 Final Project'\n",
        "with open(os.path.join(root_dir, 'songs.txt'), 'r') as data_file:\n",
        "  for line in data_file:\n",
        "    text.append(line.replace(\"d\", \" d\").split())\n",
        "test_song = text[0]\n",
        "text = text[1:]\n",
        "print(text[0])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['br', 'd316', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '48', 'd1', 'br', 'd1', '46', 'd2', '47', 'd1', 'br', 'd1', '45', 'd1', 'br', 'd1', '43', 'd2', '44', 'd1', 'br', 'd1', '42', 'd1', 'br', 'd1', '40', 'd2', '41', 'd1', 'br', 'd15', '49', 'd1', 'br', 'd1', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '40', 'd1', 'br', 'd1', '38', 'd2', '39', 'd1', 'br', 'd1', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd13', '42', 'd13', '54', 'd5', 'br', 'd4', '49', 'd9', '55', 'd1', '56', 'd2', 'br', 'd1', '57', 'd1', '58', 'd1', '59', 'd2', 'br', 'd1', '60', 'd1', '61', 'd5', 'br', 'd6', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '48', 'd1', 'br', 'd1', '46', 'd2', '47', 'd1', 'br', 'd1', '45', 'd1', 'br', 'd1', '43', 'd2', '44', 'd1', 'br', 'd1', '42', 'd1', 'br', 'd1', '40', 'd2', '41', 'd1', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd17', '42', 'd17', '54', 'd11', 'br', 'd4', '49', 'd77', 'br', 'd5', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd1', '38', 'd2', '39', 'd1', 'br', 'd1', '37', 'd65', '44', 'd65', '53', 'd65', 'br', 'd64', '42', 'd33', '47', 'd65', '54', 'd29', '59', 'd29', 'br', 'd28', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '35', 'd33', '40', 'd33', '52', 'd33', 'br', 'd20', '42', 'd5', 'br', 'd8', '42', 'd5', 'br', 'd4', '37', 'd65', '44', 'd65', '49', 'd65', '53', 'd65', 'br', 'd64', '42', 'd33', '47', 'd57', '54', 'd29', '59', 'd29', 'br', 'd28', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '35', 'd33', '40', 'd29', '52', 'd25', 'br', 'd4', '38', 'd5', 'br', 'd20', '42', 'd5', '49', 'd5', '54', 'd9', 'br', 'd4', '47', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '36', 'd2', '47', 'd2', '48', 'd1', 'br', 'd1', '35', 'd2', '46', 'd2', 'br', 'd1', '33', 'd2', '34', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '32', 'd2', '43', 'd2', 'br', 'd1', '30', 'd2', '31', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '29', 'd2', '40', 'd2', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd49', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd13', '42', 'd13', 'br', 'd4', '49', 'd9', '55', 'd1', '56', 'd2', '57', 'd2', 'br', 'd1', '58', 'd1', '59', 'd2', '60', 'd2', 'br', 'd1', '61', 'd5', 'br', 'd6', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd2', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd2', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '40', 'd2', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd17', '42', 'd14', '54', 'd7', 'br', 'd4', '49', 'd9', 'br', 'd2', '44', 'd1', '45', 'd2', '46', 'd2', 'br', 'd1', '47', 'd4', '48', 'd3', 'br', 'd3', '45', 'd2', '46', 'd1', 'br', 'd1', '44', 'd2', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', 'br', 'd1', '39', 'd2', '40', 'd1', 'br', 'd1', '38', 'd2', 'br', 'd1', '37', 'd53', '44', 'd51', '49', 'd51', '53', 'd51', 'br', 'd12', '35', 'd5', 'br', 'd16', '35', 'd5', 'br', 'd24', '28', 'd5', '40', 'd5', '47', 'd5', '52', 'd5', 'br', 'd4', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd15', '42', 'd18', '49', 'd18', '54', 'd18', 'br', 'd14', '31', 'd1', '33', 'd2', 'br', 'd1', '35', 'd2', 'br', 'd1', '37', 'd1', '38', 'd2', 'br', 'd1', '39', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd6', '33', 'd5', '45', 'd5', '52', 'd5', '57', 'd5', 'br', 'd4', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd8', '35', 'd7', '47', 'd7', '54', 'd5', '59', 'd5', 'br', 'd8', '25', 'd5', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '28', 'd5', '35', 'd13', '40', 'd13', '47', 'd13', '52', 'd13', 'br', 'd4', '30', 'd5', '42', 'd5', 'br', 'd4', '28', 'd5', 'br', 'd4', '25', 'd5', '32', 'd5', '37', 'd57', '44', 'd55', '49', 'd55', 'br', 'd4', '53', 'd51', 'br', 'd12', '35', 'd5', 'br', 'd16', '35', 'd5', 'br', 'd24', '28', 'd5', '40', 'd5', '47', 'd5', '52', 'd5', 'br', 'd4', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd15', '42', 'd18', '49', 'd18', '54', 'd18', 'br', 'd14', '31', 'd1', '33', 'd2', 'br', 'd1', '35', 'd2', 'br', 'd1', '37', 'd1', '38', 'd2', 'br', 'd1', '39', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd6', '33', 'd5', '45', 'd5', '52', 'd5', '57', 'd5', 'br', 'd4', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd8', '35', 'd7', '47', 'd7', '54', 'd5', '59', 'd5', 'br', 'd8', '25', 'd5', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '28', 'd5', '35', 'd13', '40', 'd13', '47', 'd13', '52', 'd13', 'br', 'd4', '30', 'd5', '42', 'd9', 'br', 'd8', '25', 'd5', '32', 'd5', '37', 'd57', '44', 'd55', '49', 'd55']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposes music to generate more data\n",
        "transposed_songs = []\n",
        "for song in text:\n",
        "  for t in range(12):\n",
        "    transp = []\n",
        "    for note in song:\n",
        "      if note[0] != 'b' and note[0] != 'd':\n",
        "        transp.append(str(int(note) + t))\n",
        "      else:\n",
        "        transp.append(note)\n",
        "    transposed_songs.append(transp)\n"
      ],
      "metadata": {
        "id": "sFhrLVCGh-zb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(transposed_songs))\n",
        "print(str(int('1')+1))\n",
        "print(transposed_songs[0])\n",
        "print(transposed_songs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRrmApCYkufJ",
        "outputId": "d807d89c-b40b-4972-c212-00cb328ee63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29052\n",
            "2\n",
            "['br', 'd316', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '48', 'd1', 'br', 'd1', '46', 'd2', '47', 'd1', 'br', 'd1', '45', 'd1', 'br', 'd1', '43', 'd2', '44', 'd1', 'br', 'd1', '42', 'd1', 'br', 'd1', '40', 'd2', '41', 'd1', 'br', 'd15', '49', 'd1', 'br', 'd1', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '40', 'd1', 'br', 'd1', '38', 'd2', '39', 'd1', 'br', 'd1', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd13', '42', 'd13', '54', 'd5', 'br', 'd4', '49', 'd9', '55', 'd1', '56', 'd2', 'br', 'd1', '57', 'd1', '58', 'd1', '59', 'd2', 'br', 'd1', '60', 'd1', '61', 'd5', 'br', 'd6', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '48', 'd1', 'br', 'd1', '46', 'd2', '47', 'd1', 'br', 'd1', '45', 'd1', 'br', 'd1', '43', 'd2', '44', 'd1', 'br', 'd1', '42', 'd1', 'br', 'd1', '40', 'd2', '41', 'd1', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd17', '42', 'd17', '54', 'd11', 'br', 'd4', '49', 'd77', 'br', 'd5', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd1', '38', 'd2', '39', 'd1', 'br', 'd1', '37', 'd65', '44', 'd65', '53', 'd65', 'br', 'd64', '42', 'd33', '47', 'd65', '54', 'd29', '59', 'd29', 'br', 'd28', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '35', 'd33', '40', 'd33', '52', 'd33', 'br', 'd20', '42', 'd5', 'br', 'd8', '42', 'd5', 'br', 'd4', '37', 'd65', '44', 'd65', '49', 'd65', '53', 'd65', 'br', 'd64', '42', 'd33', '47', 'd57', '54', 'd29', '59', 'd29', 'br', 'd28', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '35', 'd33', '40', 'd29', '52', 'd25', 'br', 'd4', '38', 'd5', 'br', 'd20', '42', 'd5', '49', 'd5', '54', 'd9', 'br', 'd4', '47', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '36', 'd2', '47', 'd2', '48', 'd1', 'br', 'd1', '35', 'd2', '46', 'd2', 'br', 'd1', '33', 'd2', '34', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '32', 'd2', '43', 'd2', 'br', 'd1', '30', 'd2', '31', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '29', 'd2', '40', 'd2', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd49', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd13', '42', 'd13', 'br', 'd4', '49', 'd9', '55', 'd1', '56', 'd2', '57', 'd2', 'br', 'd1', '58', 'd1', '59', 'd2', '60', 'd2', 'br', 'd1', '61', 'd5', 'br', 'd6', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd12', '35', 'd5', '47', 'd5', '54', 'd5', 'br', 'd4', '37', 'd5', '49', 'd5', '56', 'd5', 'br', 'd4', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd2', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd2', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd1', '40', 'd2', 'br', 'd23', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd29', '42', 'd29', '49', 'd25', '54', 'd37', 'br', 'd28', '31', 'd17', '43', 'd17', '55', 'd17', 'br', 'd16', '30', 'd17', '42', 'd14', '54', 'd7', 'br', 'd4', '49', 'd9', 'br', 'd2', '44', 'd1', '45', 'd2', '46', 'd2', 'br', 'd1', '47', 'd4', '48', 'd3', 'br', 'd3', '45', 'd2', '46', 'd1', 'br', 'd1', '44', 'd2', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', 'br', 'd1', '39', 'd2', '40', 'd1', 'br', 'd1', '38', 'd2', 'br', 'd1', '37', 'd53', '44', 'd51', '49', 'd51', '53', 'd51', 'br', 'd12', '35', 'd5', 'br', 'd16', '35', 'd5', 'br', 'd24', '28', 'd5', '40', 'd5', '47', 'd5', '52', 'd5', 'br', 'd4', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd15', '42', 'd18', '49', 'd18', '54', 'd18', 'br', 'd14', '31', 'd1', '33', 'd2', 'br', 'd1', '35', 'd2', 'br', 'd1', '37', 'd1', '38', 'd2', 'br', 'd1', '39', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd6', '33', 'd5', '45', 'd5', '52', 'd5', '57', 'd5', 'br', 'd4', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd8', '35', 'd7', '47', 'd7', '54', 'd5', '59', 'd5', 'br', 'd8', '25', 'd5', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '28', 'd5', '35', 'd13', '40', 'd13', '47', 'd13', '52', 'd13', 'br', 'd4', '30', 'd5', '42', 'd5', 'br', 'd4', '28', 'd5', 'br', 'd4', '25', 'd5', '32', 'd5', '37', 'd57', '44', 'd55', '49', 'd55', 'br', 'd4', '53', 'd51', 'br', 'd12', '35', 'd5', 'br', 'd16', '35', 'd5', 'br', 'd24', '28', 'd5', '40', 'd5', '47', 'd5', '52', 'd5', 'br', 'd4', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd15', '42', 'd18', '49', 'd18', '54', 'd18', 'br', 'd14', '31', 'd1', '33', 'd2', 'br', 'd1', '35', 'd2', 'br', 'd1', '37', 'd1', '38', 'd2', 'br', 'd1', '39', 'd2', 'br', 'd1', '40', 'd1', 'br', 'd6', '33', 'd5', '45', 'd5', '52', 'd5', '57', 'd5', 'br', 'd4', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd8', '35', 'd7', '47', 'd7', '54', 'd5', '59', 'd5', 'br', 'd8', '25', 'd5', '37', 'd5', '44', 'd5', '49', 'd5', 'br', 'd4', '28', 'd5', '35', 'd13', '40', 'd13', '47', 'd13', '52', 'd13', 'br', 'd4', '30', 'd5', '42', 'd9', 'br', 'd8', '25', 'd5', '32', 'd5', '37', 'd57', '44', 'd55', '49', 'd55']\n",
            "['br', 'd316', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd4', '49', 'd1', 'br', 'd1', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd15', '50', 'd1', 'br', 'd1', '48', 'd2', '49', 'd1', 'br', 'd1', '47', 'd1', 'br', 'd1', '45', 'd2', '46', 'd1', 'br', 'd1', '44', 'd1', 'br', 'd1', '42', 'd2', '43', 'd1', 'br', 'd1', '41', 'd1', 'br', 'd1', '39', 'd2', '40', 'd1', 'br', 'd1', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd29', '43', 'd29', '50', 'd25', '55', 'd37', 'br', 'd28', '32', 'd17', '44', 'd17', '56', 'd17', 'br', 'd16', '31', 'd13', '43', 'd13', '55', 'd5', 'br', 'd4', '50', 'd9', '56', 'd1', '57', 'd2', 'br', 'd1', '58', 'd1', '59', 'd1', '60', 'd2', 'br', 'd1', '61', 'd1', '62', 'd5', 'br', 'd6', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd4', '49', 'd1', 'br', 'd1', '47', 'd2', '48', 'd1', 'br', 'd1', '46', 'd1', 'br', 'd1', '44', 'd2', '45', 'd1', 'br', 'd1', '43', 'd1', 'br', 'd1', '41', 'd2', '42', 'd1', 'br', 'd23', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd29', '43', 'd29', '50', 'd25', '55', 'd37', 'br', 'd28', '32', 'd17', '44', 'd17', '56', 'd17', 'br', 'd16', '31', 'd17', '43', 'd17', '55', 'd11', 'br', 'd4', '50', 'd77', 'br', 'd5', '48', 'd2', '49', 'd1', 'br', 'd1', '47', 'd1', 'br', 'd1', '45', 'd2', '46', 'd1', 'br', 'd1', '44', 'd1', 'br', 'd1', '42', 'd2', 'br', 'd1', '41', 'd1', 'br', 'd1', '39', 'd2', '40', 'd1', 'br', 'd1', '38', 'd65', '45', 'd65', '54', 'd65', 'br', 'd64', '43', 'd33', '48', 'd65', '55', 'd29', '60', 'd29', 'br', 'd28', '38', 'd5', '45', 'd5', '50', 'd5', 'br', 'd4', '36', 'd33', '41', 'd33', '53', 'd33', 'br', 'd20', '43', 'd5', 'br', 'd8', '43', 'd5', 'br', 'd4', '38', 'd65', '45', 'd65', '50', 'd65', '54', 'd65', 'br', 'd64', '43', 'd33', '48', 'd57', '55', 'd29', '60', 'd29', 'br', 'd28', '38', 'd5', '45', 'd5', '50', 'd5', 'br', 'd4', '36', 'd33', '41', 'd29', '53', 'd25', 'br', 'd4', '39', 'd5', 'br', 'd20', '43', 'd5', '50', 'd5', '55', 'd9', 'br', 'd4', '48', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd4', '37', 'd2', '48', 'd2', '49', 'd1', 'br', 'd1', '36', 'd2', '47', 'd2', 'br', 'd1', '34', 'd2', '35', 'd1', '45', 'd2', '46', 'd1', 'br', 'd1', '33', 'd2', '44', 'd2', 'br', 'd1', '31', 'd2', '32', 'd1', '42', 'd2', '43', 'd1', 'br', 'd1', '30', 'd2', '41', 'd2', 'br', 'd23', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd29', '43', 'd29', '50', 'd25', '55', 'd49', 'br', 'd28', '32', 'd17', '44', 'd17', '56', 'd17', 'br', 'd16', '31', 'd13', '43', 'd13', 'br', 'd4', '50', 'd9', '56', 'd1', '57', 'd2', '58', 'd2', 'br', 'd1', '59', 'd1', '60', 'd2', '61', 'd2', 'br', 'd1', '62', 'd5', 'br', 'd6', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd12', '36', 'd5', '48', 'd5', '55', 'd5', 'br', 'd4', '38', 'd5', '50', 'd5', '57', 'd5', 'br', 'd4', '48', 'd2', '49', 'd1', 'br', 'd1', '47', 'd2', 'br', 'd1', '45', 'd2', '46', 'd1', 'br', 'd1', '44', 'd2', 'br', 'd1', '42', 'd2', '43', 'd1', 'br', 'd1', '41', 'd2', 'br', 'd23', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd29', '43', 'd29', '50', 'd25', '55', 'd37', 'br', 'd28', '32', 'd17', '44', 'd17', '56', 'd17', 'br', 'd16', '31', 'd17', '43', 'd14', '55', 'd7', 'br', 'd4', '50', 'd9', 'br', 'd2', '45', 'd1', '46', 'd2', '47', 'd2', 'br', 'd1', '48', 'd4', '49', 'd3', 'br', 'd3', '46', 'd2', '47', 'd1', 'br', 'd1', '45', 'd2', 'br', 'd1', '44', 'd1', 'br', 'd1', '42', 'd2', 'br', 'd1', '40', 'd2', '41', 'd1', 'br', 'd1', '39', 'd2', 'br', 'd1', '38', 'd53', '45', 'd51', '50', 'd51', '54', 'd51', 'br', 'd12', '36', 'd5', 'br', 'd16', '36', 'd5', 'br', 'd24', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd15', '43', 'd18', '50', 'd18', '55', 'd18', 'br', 'd14', '32', 'd1', '34', 'd2', 'br', 'd1', '36', 'd2', 'br', 'd1', '38', 'd1', '39', 'd2', 'br', 'd1', '40', 'd2', 'br', 'd1', '41', 'd1', 'br', 'd6', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd4', '36', 'd5', '48', 'd5', '55', 'd5', '60', 'd5', 'br', 'd8', '36', 'd7', '48', 'd7', '55', 'd5', '60', 'd5', 'br', 'd8', '26', 'd5', '38', 'd5', '45', 'd5', '50', 'd5', 'br', 'd4', '29', 'd5', '36', 'd13', '41', 'd13', '48', 'd13', '53', 'd13', 'br', 'd4', '31', 'd5', '43', 'd5', 'br', 'd4', '29', 'd5', 'br', 'd4', '26', 'd5', '33', 'd5', '38', 'd57', '45', 'd55', '50', 'd55', 'br', 'd4', '54', 'd51', 'br', 'd12', '36', 'd5', 'br', 'd16', '36', 'd5', 'br', 'd24', '29', 'd5', '41', 'd5', '48', 'd5', '53', 'd5', 'br', 'd4', '30', 'd5', '42', 'd5', '49', 'd5', '54', 'd5', 'br', 'd4', '31', 'd15', '43', 'd18', '50', 'd18', '55', 'd18', 'br', 'd14', '32', 'd1', '34', 'd2', 'br', 'd1', '36', 'd2', 'br', 'd1', '38', 'd1', '39', 'd2', 'br', 'd1', '40', 'd2', 'br', 'd1', '41', 'd1', 'br', 'd6', '34', 'd5', '46', 'd5', '53', 'd5', '58', 'd5', 'br', 'd4', '35', 'd5', '47', 'd5', '54', 'd5', '59', 'd5', 'br', 'd4', '36', 'd5', '48', 'd5', '55', 'd5', '60', 'd5', 'br', 'd8', '36', 'd7', '48', 'd7', '55', 'd5', '60', 'd5', 'br', 'd8', '26', 'd5', '38', 'd5', '45', 'd5', '50', 'd5', 'br', 'd4', '29', 'd5', '36', 'd13', '41', 'd13', '48', 'd13', '53', 'd13', 'br', 'd4', '31', 'd5', '43', 'd9', 'br', 'd8', '26', 'd5', '33', 'd5', '38', 'd57', '45', 'd55', '50', 'd55']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqul2N0zLWWj"
      },
      "source": [
        "# Pad songs\n",
        "def pad_songs(songs):\n",
        "  padded_songs = []\n",
        "  for line in songs:\n",
        "    if len(line) != 0:\n",
        "      song = line[:CHUNK_SZ]\n",
        "      song += [PAD_TOKEN] * (CHUNK_SZ - len(song))\n",
        "      padded_songs.append(song)\n",
        "  return padded_songs\n",
        "\n",
        "orig = pad_songs(text)\n",
        "transposed = pad_songs(transposed_songs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orRh13byKfIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7480c0-f9fe-4b76-bdc6-8d7355302675"
      },
      "source": [
        "# Create vocab\n",
        "\n",
        "tokens = []\n",
        "for s in transposed: tokens.extend(s)\n",
        "all_words = sorted(list(set([STOP_TOKEN,PAD_TOKEN] + tokens)))\n",
        "\n",
        "vocab =  {word:i for i,word in enumerate(all_words)}\n",
        "VOCAB_SZ = len(vocab)\n",
        "print(VOCAB_SZ)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAGJT3AQOriU"
      },
      "source": [
        "orig_ids = np.asarray(np.stack([[vocab[word] for word in song] for song in orig]))\n",
        "transposed_ids = np.asarray(np.stack([[vocab[word] for word in song] for song in transposed]))\n",
        "test_ids = np.asarray(np.stack([vocab[word] for word in test_song]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(orig_ids)\n",
        "print(transposed_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY_JTxX-pOBc",
        "outputId": "821fcc51-d208-4a7c-9f6b-ca5f5933c55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[141 397  68 ... 468  60 517]\n",
            " [141 401  61 ... 142  82 590]\n",
            " [ 64 240  90 ... 445  96 445]\n",
            " ...\n",
            " [ 86 413  93 ... 413  87 240]\n",
            " [141 401  72 ... 385 141 672]\n",
            " [141 401  80 ... 277  71 384]]\n",
            "[[141 397  68 ... 468  60 517]\n",
            " [141 397  69 ... 468  61 517]\n",
            " [141 397  70 ... 468  63 517]\n",
            " ...\n",
            " [141 401  90 ... 277  81 384]\n",
            " [141 401  91 ... 277  82 384]\n",
            " [141 401  92 ... 277  83 384]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jGYG5x6golj"
      },
      "source": [
        "# Transformer model\n",
        "def Attention_Matrix(K, Q, use_mask=False):\n",
        "\t\"\"\"\n",
        "\tSTUDENT MUST WRITE:\n",
        "\tThis functions runs a single attention head.\n",
        "\t:param K: is [batch_size x window_size_keys x embedding_size]\n",
        "\t:param Q: is [batch_size x window_size_queries x embedding_size]\n",
        "\t:return: attention matrix\n",
        "\t\"\"\"\n",
        "\t\n",
        "\twindow_size_queries = Q.get_shape()[1] # window size of queries\n",
        "\twindow_size_keys = K.get_shape()[1] # window size of keys\n",
        "\troot_dk = window_size_keys ** 0.5\n",
        "\tmask = tf.convert_to_tensor(value=np.transpose(np.tril(np.ones((window_size_queries,window_size_keys))*np.NINF,-1),(1,0)),dtype=tf.float32)\n",
        "\tatten_mask = tf.tile(tf.reshape(mask,[-1,window_size_queries,window_size_keys]),[tf.shape(input=K)[0],1,1])\n",
        "\n",
        "\tunmasked = tf.math.scalar_mul(root_dk, tf.matmul(Q, K, transpose_b=True))\n",
        "\n",
        "\tmasked = tf.add(unmasked, atten_mask) if use_mask else unmasked\n",
        "\treturn tf.nn.softmax(masked)\n",
        "\n",
        "\n",
        "class Atten_Head(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, input_size, output_size, use_mask):\t\t\n",
        "\t\tsuper(Atten_Head, self).__init__()\n",
        "\n",
        "\t\tself.use_mask = use_mask\n",
        "\n",
        "\t\tself.WK = self.add_weight(shape=(input_size, output_size), dtype=tf.float32, trainable=True)\n",
        "\t\tself.WQ = self.add_weight(shape=(input_size, output_size), dtype=tf.float32, trainable=True)\n",
        "\t\tself.WV = self.add_weight(shape=(input_size, output_size), dtype=tf.float32, trainable=True)\n",
        "\t\t\n",
        "\t@tf.function\n",
        "\tdef call(self, inputs_for_keys, inputs_for_values, inputs_for_queries):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\t:param inputs_for_keys: tensor of [batch_size x [ENG/FRN]_WINDOW_SIZE x input_size ]\n",
        "\t\t:param inputs_for_values: tensor of [batch_size x [ENG/FRN]_WINDOW_SIZE x input_size ]\n",
        "\t\t:param inputs_for_queries: tensor of [batch_size x [ENG/FRN]_WINDOW_SIZE x input_size ]\n",
        "\t\t:return: tensor of [BATCH_SIZE x (ENG/FRN)_WINDOW_SIZE x output_size ]\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tK = tf.tensordot(inputs_for_keys, self.WK, axes=[[2], [1]])\n",
        "\t\tV = tf.tensordot(inputs_for_keys, self.WV, axes=[[2], [1]])\n",
        "\t\tQ = tf.tensordot(inputs_for_keys, self.WQ, axes=[[2], [1]])\n",
        "\n",
        "\t\treturn tf.matmul(Attention_Matrix(K, Q, self.use_mask), V)\n",
        "\n",
        "class Feed_Forwards(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, emb_sz):\n",
        "\t\tsuper(Feed_Forwards, self).__init__()\n",
        "\n",
        "\t\tself.layer_1 = tf.keras.layers.Dense(emb_sz,activation='relu')\n",
        "\t\tself.layer_2 = tf.keras.layers.Dense(emb_sz)\n",
        "\n",
        "\t@tf.function\n",
        "\tdef call(self, inputs):\n",
        "\t\tlayer_1_out = self.layer_1(inputs)\n",
        "\t\tlayer_2_out = self.layer_2(layer_1_out)\n",
        "\t\treturn layer_2_out\n",
        "\n",
        "class Transformer_Block(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, emb_sz, is_decoder):\n",
        "\t\tsuper(Transformer_Block, self).__init__()\n",
        "\n",
        "\t\tself.ff_layer = Feed_Forwards(emb_sz)\n",
        "\t\tself.self_atten = Atten_Head(emb_sz,emb_sz,use_mask=is_decoder)\n",
        "\t\tself.is_decoder = is_decoder\n",
        "\t\tif self.is_decoder:\n",
        "\t\t\tself.self_context_atten = Atten_Head(emb_sz,emb_sz,use_mask=False)\n",
        "\n",
        "\t\tself.layer_norm = tf.keras.layers.LayerNormalization(axis=-1)\n",
        "\n",
        "\t@tf.function\n",
        "\tdef call(self, inputs, context=None):\n",
        "\n",
        "\t\tatten_out = self.self_atten(inputs,inputs,inputs)\n",
        "\t\tatten_out+=inputs\n",
        "\t\tatten_normalized = self.layer_norm(atten_out)\n",
        "\n",
        "\t\tif self.is_decoder:\n",
        "\t\t\tassert context is not None,\"Decoder blocks require context\"\n",
        "\t\t\tcontext_atten_out = self.self_context_atten(context,context,atten_normalized)\n",
        "\t\t\tcontext_atten_out+=atten_normalized\n",
        "\t\t\tatten_normalized = self.layer_norm(context_atten_out)\n",
        "\n",
        "\t\tff_out=self.ff_layer(atten_normalized)\n",
        "\t\tff_out+=atten_normalized\n",
        "\t\tff_norm = self.layer_norm(ff_out)\n",
        "\n",
        "\t\treturn tf.nn.relu(ff_norm)\n",
        "\n",
        "class Position_Encoding_Layer(tf.keras.layers.Layer):\n",
        "\tdef __init__(self, window_sz, emb_sz):\n",
        "\t\tsuper(Position_Encoding_Layer, self).__init__()\n",
        "\t\tself.positional_embeddings = self.add_weight(\"pos_embed\",shape=[window_sz, emb_sz])\n",
        "\n",
        "\t@tf.function\n",
        "\tdef call(self, x):\n",
        "\t\t\"\"\"\n",
        "\t\tAdds positional embeddings to word embeddings.    \n",
        "\t\t:param x: [BATCH_SIZE x (ENG/FRN)_WINDOW_SIZE x EMBEDDING_SIZE ] the input embeddings fed to the encoder\n",
        "\t\t:return: [BATCH_SIZE x (ENG/FRN)_WINDOW_SIZE x EMBEDDING_SIZE ] new word embeddings with added positional encodings\n",
        "\t\t\"\"\"\n",
        "\t\treturn x+self.positional_embeddings\n",
        "\n",
        "class Transformer_Seq2Seq(tf.keras.Model):\n",
        "\tdef __init__(self, window_sz, vocab_sz):\n",
        "\n",
        "\t\t######vvv DO NOT CHANGE vvv##################\n",
        "\t\tsuper(Transformer_Seq2Seq, self).__init__()\n",
        "\n",
        "\t\tself.vocab_sz = vocab_sz\n",
        "\t\tself.window_sz = window_sz \n",
        "\n",
        "\t\t# Define batch size and optimizer/learning rate\n",
        "\t\tself.batch_size = 10\n",
        "\t\tself.embedding_size = 100\n",
        "\t\tself.learning_rate = 0.0015\n",
        "\t\tself.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "\n",
        "\t\t# Define english and french embedding layers:\n",
        "\t\tself.embedding = tf.keras.layers.Embedding(self.vocab_sz, self.embedding_size)\n",
        "\t\t# Create positional encoder layers\n",
        "\t\tself.position = Position_Encoding_Layer(self.window_sz, self.embedding_size)\n",
        "\t\t# Define encoder and decoder layers:\n",
        "\t\tself.encoder = Transformer_Block(self.embedding_size, False)\n",
        "\t\tself.decoder = Transformer_Block(self.embedding_size, True)\n",
        "\t\t# Define dense layer(s)\n",
        "\t\tself.dense1 = tf.keras.layers.Dense(100, activation='relu')\n",
        "\t\tself.dense2 = tf.keras.layers.Dense(self.vocab_sz, activation='softmax')\n",
        "\n",
        "\t@tf.function\n",
        "\tdef call(self, encoder_input, decoder_input):\n",
        "\t\t\"\"\"\n",
        "\t\t:param encoder_input: batched ids corresponding to french sentences\n",
        "\t\t:param decoder_input: batched ids corresponding to english sentences\n",
        "\t\t:return prbs: The 3d probabilities as a tensor, [batch_size x window_size x english_vocab_size]\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t#1) Add the positional embeddings to french sentence embeddings\n",
        "\t\tlocated_given = self.position(self.embedding(encoder_input))\n",
        "\t\t#2) Pass the french sentence embeddings to the encoder\n",
        "\t\tencoded = self.encoder(located_given)\n",
        "\t\t#3) Add positional embeddings to the english sentence embeddings\n",
        "\t\tlocated_wanted = self.position(self.embedding(decoder_input))\n",
        "\t\t#4) Pass the english embeddings and output of your encoder, to the decoder\n",
        "\t\tdecoded = self.decoder(located_wanted, encoded)\n",
        "\t\t#5) Apply dense layer(s) to the decoder out to generate probabilities\n",
        "\t\tprobabilities = self.dense2(self.dense1(decoded))\n",
        "\t\treturn probabilities\n",
        "\n",
        "\tdef loss(self, probs, labels):\n",
        "\t\t\t\t\treturn tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(labels, probs))\n",
        "\t\t\n",
        "def train(model, inputs):\n",
        "\t\"\"\"\n",
        "\tInputs: list of sequence of notes as tokens\n",
        "\t\"\"\"\n",
        "\tunshuffled_inputs = []\n",
        "\tsequed = []\n",
        "\tdef seq_window(sequences, window_size):\n",
        "\t\tdata = []\n",
        "\t\tfor ind in range(len(sequences)):\n",
        "\t\t\tseq_len = len(sequences[ind])\n",
        "\t\t\tif seq_len < window_size:\n",
        "\t\t\t\traise Exception(\"Window too large for sequence\")\n",
        "\t\t\twindows = []\n",
        "\t\t\tfor window in range(seq_len - window_size + 1):\n",
        "\t\t\t\twindows.append((ind, window))\n",
        "\t\t\tdata += windows\n",
        "\t\treturn data\n",
        "\t\n",
        "\tdef to_window(bat, inputs, is_label):\n",
        "\t\tnew_windows = np.zeros([model.batch_size, WINDOW_SZ])\n",
        "\t\tfor i in range(len(bat)):\n",
        "\t\t\tinds = bat[i]\n",
        "\t\t\tseq = inputs[inds[0]]\n",
        "\t\t\t\n",
        "\t\t\tif is_label:\n",
        "\t\t\t\tnew_windows[i] = seq[inds[1]+1:inds[1]+1+WINDOW_SZ]\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_windows[i] = seq[inds[1]:inds[1]+WINDOW_SZ]\n",
        "\t\treturn new_windows\n",
        "\n",
        "\tunshuffled_inputs = seq_window(inputs[:, :-1], WINDOW_SZ)\n",
        "\tprint(unshuffled_inputs[0])\n",
        "\tindices = np.arange(len(unshuffled_inputs))\n",
        "\tnp.random.shuffle(indices)\n",
        "\n",
        "\tsequed = np.take(np.asarray(unshuffled_inputs), indices, axis=0)\n",
        "\tprint(sequed[0])\n",
        "\tlass = 0\n",
        "\tlosses = []\n",
        "\tfor batch in range(math.floor(len(inputs) / model.batch_size)):\n",
        "\t\tbatch_1 = sequed[batch * model.batch_size:batch * model.batch_size + model.batch_size]\n",
        "\t\tbatch_en_in = to_window(batch_1, inputs, False)\n",
        "\t\t#batch_de_in = to_window(batch_1, inputs, False)\n",
        "\t\tbatch_de_la = to_window(batch_1, inputs, True)\n",
        "\n",
        "\t\tif batch%20 == 0:\n",
        "\t\t\tprint(lass / 20)\n",
        "\t\t\tlass = 0\n",
        "\t\telse:\n",
        "\t\t\tpass\t\n",
        "\t\twith tf.GradientTape() as tape:\n",
        "\t\t\tpredictions = model.call(batch_en_in, batch_en_in)\n",
        "\t\t\tloss = model.loss(predictions, batch_de_la)\n",
        "\t\t\tlass += loss\n",
        "\t\t\tlosses.append(loss)\n",
        "\t\t\tgradients = tape.gradient(loss, model.trainable_variables)\n",
        "\t\t\tmodel.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\treturn losses\n",
        "\n",
        "def generate_sentence(sample, length, vocab, model, sample_n=10):\n",
        "\t#NOTE: Feel free to play around with different sample_n values\n",
        "\treverse_vocab = {idx: word for word, idx in vocab.items()}\n",
        "\tnotes = [sample]\n",
        "\tnext_input = np.asarray([sample])\n",
        "\tsong = np.asarray([sample])\n",
        "\n",
        "\tfor i in range(length):\n",
        "\t\tlogits = model.call(next_input, next_input)\n",
        "\t\tlogits = np.array(logits[0, WINDOW_SZ - 1,:])\n",
        "\t\ttop_n = np.argsort(logits)[-sample_n:]\t\t\t\n",
        "\t\tn_logits = np.exp(logits[top_n])/np.exp(logits[top_n]).sum()\n",
        "\t\tout_index = np.random.choice(top_n,p=n_logits)\n",
        "\t\tsong = np.append(song, [[out_index]], axis=1)\n",
        "\t\tnext_input = np.append(next_input[:, 1:], [[out_index]], axis=1)\n",
        "\n",
        "\treturn song\n",
        "\n",
        "\n",
        "model = Transformer_Seq2Seq(WINDOW_SZ, VOCAB_SZ)\n",
        "\n",
        "\n",
        "\t\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZHgD_rPEMoN"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "losses = []\n",
        "for i in range(5):\n",
        "  losses += train(model, transposed_ids)\n",
        "for i in range(3):\n",
        " losses += train(model, orig_ids)\n",
        "plt.plot()\n",
        "plt.show(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = orig_ids[50, :100]\n",
        "reverse_vocab = {idx: word for word, idx in vocab.items()}\n",
        "string = \"\"\n",
        "for id in generate_sentence(sample, 400, vocab, model).tolist()[0]:\n",
        "  string += str(reverse_vocab[id]) + \" \"\n",
        "\n",
        "print(string)\n",
        "\n"
      ],
      "metadata": {
        "id": "x5z6GDBsJtHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fa4ab7-55e4-4749-ace3-4e952d8aa6ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "br d42 36 d31 48 d34 52 d6 55 d6 br d8 52 d6 55 d5 br d8 52 d6 55 d5 br d8 52 d6 55 d5 br d8 29 d31 41 d33 53 d6 57 d5 br d4 48 d6 br d4 53 d6 57 d6 br d4 48 d6 br d4 53 d6 57 d6 br d4 48 d4 br d4 57 d4 br d2 58 d4 br d2 59 d4 br d2 60 d2 br d2 36 d32 48 d34 52 d6 55 d5 br d8 52 d6 55 d5 br d8 52 d6 55 d5 64 d3 br d1 40 d1 60 d1 55 d3 65 d10 70 d2 70 d2 72 d7 79 d6 91 d6 95 d1 96 d5 96 d1 103 d3 105 d8 95 d8 95 d2 93 d2 103 d4 98 d8 100 d7 107 d8 98 d6 96 d9 98 d7 103 d8 108 d5 104 d10 100 d10 91 d7 br d12 br d4 55 d3 96 d6 100 d10 105 d3 108 d9 br d6 52 d8 60 d5 84 d9 93 d2 108 d4 br d2 48 d8 60 d10 br d8 60 d2 64 d2 69 d6 79 d7 91 d1 95 d3 91 d2 103 d5 100 d4 96 d2 br d5 48 d3 br d9 60 d8 96 d1 96 d5 103 d1 96 d2 94 d1 103 d7 108 d2 105 d3 96 d4 100 d6 95 d4 98 d5 96 d5 100 d9 br d2 br d1 36 d9 60 d7 65 d2 108 d5 106 d5 96 d4 br d9 100 d4 98 d5 95 d1 97 d13 93 d1 98 d8 97 d3 95 d4 95 d2 br d2 99 d3 94 d5 94 d7 br d4 99 d5 94 d10 99 d7 104 d9 br d7 94 d2 93 d7 95 d9 107 d5 102 d3 95 d9 104 d4 99 d13 107 d1 99 d1 br d3 56 d8 56 d10 60 d9 104 d8 107 d4 95 d1 95 d2 103 d8 br d2 56 d7 99 d1 br d5 102 d3 97 d9 95 d2 100 d6 100 d6 br d2 107 d5 103 d2 97 d10 104 d4 99 d6 97 d7 99 d5 100 d5 99 d7 104 d10 100 d1 99 d10 107 d3 110 d1 100 d5 107 d5 102 d7 109 d3 br d6 br d9 40 d6 br d2 52 d3 107 d4 br d4 35 d5 102 d2 102 d1 br d2 28 d1 95 d1 br d7 40 d8 40 d7 br d3 28 d7 40 d5 47 d5 br d2 35 d8 59 d9 71 d13 83 d5 97 d7 br d9 35 d2 52 d4 100 d4 52 d10 57 d5 59 d4 66 d2 68 d3 78 d3 90 d6 90 d2 97 d10 95 d8 102 d3 97 d4 104 d6 100 d9 95 d6 102 d7 100 d10 br d5 95 d6 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_vocab = {idx: word for word, idx in vocab.items()}\n",
        "for id in song_ids[0, :20]: print(reverse_vocab[id]) "
      ],
      "metadata": {
        "id": "M0RSltFBanhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "54f37d70-b7c9-43cb-d011-ff7841b15229"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-da50cb9e4f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreverse_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msong_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'song_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes in a string of tokens representing one song, transforms into a pianoroll matrix\n",
        "def token_to_music(tokens):\n",
        "  token_list = tokens.replace(\" d\", \"d\").split()\n",
        "  mat = np.full([1, 128], False)\n",
        "  note = 0\n",
        "  for tk in token_list:\n",
        "    pitch_dur = tk.split('d')\n",
        "    if len(pitch_dur) == 2:\n",
        "      pitch = tk.split('d')[0]\n",
        "      dur = int(tk.split('d')[1])\n",
        "      if pitch == 'br':\n",
        "        note += dur\n",
        "      else:\n",
        "        for i in range(dur):\n",
        "          while note + i >= mat.shape[0]:\n",
        "            mat = np.append(mat, np.full([1, 128], False), axis = 0)\n",
        "          mat[note + i, int(pitch)] = True\n",
        "  return mat\n",
        "\n",
        "track = pypianoroll.BinaryTrack(pianoroll=token_to_music(string)) #fill in \"\" with tokens \n",
        "                                \n",
        "pypianoroll.write(os.path.join(root_dir, \"test_output3.mid\"), pypianoroll.Multitrack(resolution = 8, tempo = np.full([200, 1], 120), tracks = [track]))\n",
        "\n",
        "token_to_music(string)"
      ],
      "metadata": {
        "id": "1iWlTnydkpSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b52a4e-9840-4409-f7f4-ad542ad8939a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}