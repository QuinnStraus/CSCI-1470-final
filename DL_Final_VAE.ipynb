{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Final VAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuinnStraus/CSCI-1470-final/blob/main/DL_Final_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT0_TItcESTP"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Fi86GSEMgb",
        "outputId": "cc636a75-cfa1-473f-fc11-094689c78db3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8w98EgLLUV"
      },
      "source": [
        "STOP_TOKEN = '<stop>'\n",
        "PAD_TOKEN = '<pad>'\n",
        "\n",
        "WINDOW_SZ = 200\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8-DOLEAEdod"
      },
      "source": [
        "# Convert Text to array\n",
        "\n",
        "text = []\n",
        "root_dir = 'gdrive/Shared drives/CSCI1470 Final Project'\n",
        "with open(os.path.join(root_dir, 'songs.txt'), 'r') as data_file:\n",
        "  for line in data_file:\n",
        "    text.append(line.split())\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqul2N0zLWWj",
        "outputId": "65601234-6405-43b2-d7dd-f91471e15431"
      },
      "source": [
        "# Pad songs\n",
        "\n",
        "padded_songs = []\n",
        "for line in text:\n",
        "  if len(line) != 0:\n",
        "    song = line[:WINDOW_SZ]\n",
        "    song += [STOP_TOKEN] + [PAD_TOKEN] * (WINDOW_SZ - len(song)-1)\n",
        "    padded_songs.append(song)\n",
        "print([len(padded_songs[i])for i in range(9)])\n",
        "print(padded_songs[7])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
            "['G#3d4/3', 'br', 'C4d1.5', 'E-4d1.5', 'G#4d1.5', 'br', 'F2d1.25', 'br', 'G#2d1.0', 'br', 'C3d0.75', 'br', 'E-3d1.0', 'br', 'G#3d2/3', 'br', 'C4d0.25', 'br', 'E-4d0.0', 'br', 'F3d1/3', 'br', 'C#4d4/3', 'br', 'F4d2.25', 'G#4d2.25', 'br', 'C#5d1.75', 'br', 'B-2d2.0', 'br', 'C#3d1.5', 'br', 'F3d1.0', 'br', 'G#3d1.0', 'br', 'C#4d1.0', 'br', 'F3d0.75', 'br', 'G#3d1/3', 'G#4d1/3', 'br', 'B-2d1/3', 'br', 'E-2d0.5', 'br', 'G4d2/3', 'br', 'B-2d2/3', 'br', 'G3d0.75', 'br', 'E-4d1.0', 'br', 'G4d1/3', 'br', 'E-3d2/3', 'br', 'D4d0.5', 'G4d0.5', 'br', 'E-3d0.5', 'br', 'C#4d0.25', 'G4d0.25', 'br', 'E-3d0.5', 'br', 'G#2d1.5', 'br', 'C4d1.75', 'br', 'G4d1.75', 'br', 'E-3d1.75', 'br', 'C5d2.5', 'br', 'G3d2.5', 'br', 'C4d0.75', 'br', 'E-3d1/3', 'br', 'E-3d0.75', 'br', 'G4d1/3', 'br', 'C#2d0.75', 'br', 'F4d0.75', 'br', 'G#2d0.75', 'br', 'G#3d1/3', 'F4d1/3', 'br', 'C#4d0.5', 'br', 'C#3d0.25', 'br', 'C#4d1/3', 'br', 'G#3d0.5', 'br', 'F4d0.25', 'br', 'F3d0.25', 'br', 'G#3d0.25', 'br', 'F4d1/3', 'br', 'D3d0.5', 'br', 'B3d0.5', 'F4d0.5', 'br', 'G2d4/3', 'br', 'D4d0.75', 'br', 'D3d1.0', 'br', 'F4d0.75', 'B3d0.75', 'br', 'B4d1.0', 'br', 'F3d0.75', 'br', 'B3d0.0', 'br', 'D3d1/3', 'br', 'F4d0.25', 'br', 'G2d1/3', 'br', 'A2d0.5', 'br', 'B3d0.75', 'br', 'E4d1.0', 'br', 'C2d1.0', 'br', 'G2d0.75', 'br', 'C3d2/3', 'br', 'G3d1.0', 'br', 'B3d1.0', 'br', 'E4d1.0', 'br', 'G4d1.0', 'br', 'B4d1.0', 'br', 'E5d1.0', 'br', 'G5d1.0', 'br', 'B5d1.0', 'br', 'E6d1.0', 'br', 'G6d1.25', 'br', 'B6d4/3', 'br', 'E7d1.5', 'br', 'G7d1.5', 'br', 'C3d0.75', 'br', 'G2d1.25', 'br', 'C3d1.0', 'br', 'E-3d2/3', 'br', 'G3d0.25', 'br', 'E-3d0.25', 'G3d0.25', 'br', 'B-3d4/3', 'br', 'E-4d1.25', 'br', 'C2d1.0', 'br', 'G2d0.75', 'br', '<stop>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COz7YDAGPbdq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orRh13byKfIw"
      },
      "source": [
        "# Create vocab\n",
        "\n",
        "tokens = []\n",
        "for s in padded_songs: tokens.extend(s)\n",
        "all_words = sorted(list(set([STOP_TOKEN,PAD_TOKEN] + tokens)))\n",
        "\n",
        "vocab =  {word:i for i,word in enumerate(all_words)}\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAGJT3AQOriU",
        "outputId": "38874132-7d95-4ea9-f6c2-3dda91a30aa2"
      },
      "source": [
        "song_ids = np.stack([[vocab[word] for word in song] for song in padded_songs])\n",
        "print(song_ids)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[165 170 241 ...  25 241   1]\n",
            " [ 64 159 241 ...  64 159   1]\n",
            " [155 241 155 ... 155 241   1]\n",
            " ...\n",
            " [ 75 241 108 ... 226 241   1]\n",
            " [207 241  79 ... 218 241   1]\n",
            " [155 241 164 ... 158 162   1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jGYG5x6golj"
      },
      "source": [
        "class Transformer_Seq2Seq(tf.keras.Model):\n",
        "\tdef __init__(self, window_sz, vocab_sz):\n",
        "\n",
        "\t\t######vvv DO NOT CHANGE vvv##################\n",
        "\t\tsuper(Transformer_Seq2Seq, self).__init__()\n",
        "\n",
        "\t\tself.vocab_sz = vocab_sz\n",
        "\t\tself.window_sz = window_sz \n",
        "\n",
        "\t\t# TODO:\n",
        "\t\t# 1) Define any hyperparameters\n",
        "\t\t# 2) Define embeddings, encoder, decoder, and feed forward layers\n",
        "\n",
        "\t\t# Define batch size and optimizer/learning rate\n",
        "\t\tself.batch_size = 100\n",
        "\t\tself.embedding_size = 32\n",
        "\t\tself.learning_rate = 0.001\n",
        "\t\tself.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "\n",
        "\t\t# Define english and french embedding layers:\n",
        "\t\tself.fr_embedding = tf.keras.layers.Embedding(french_vocab_size, self.embedding_size)\n",
        "\t\tself.en_embedding = tf.keras.layers.Embedding(english_vocab_size, self.embedding_size)\n",
        "\t\t# Create positional encoder layers\n",
        "\t\tself.position_fr = transformer.Position_Encoding_Layer(self.french_window_size, self.embedding_size)\n",
        "\t\tself.position_en = transformer.Position_Encoding_Layer(self.english_window_size, self.embedding_size)\n",
        "\t\t# Define encoder and decoder layers:\n",
        "\t\tself.encoder = transformer.Transformer_Block(self.embedding_size, False)\n",
        "\t\tself.decoder = transformer.Transformer_Block(self.embedding_size, True)\n",
        "\t\t# Define dense layer(s)\n",
        "\t\tself.dense2 = tf.keras.layers.Dense(self.english_vocab_size, activation='softmax')\n",
        "\n",
        "\t@tf.function\n",
        "\tdef call(self, encoder_input, decoder_input):\n",
        "\t\t\"\"\"\n",
        "\t\t:param encoder_input: batched ids corresponding to french sentences\n",
        "\t\t:param decoder_input: batched ids corresponding to english sentences\n",
        "\t\t:return prbs: The 3d probabilities as a tensor, [batch_size x window_size x english_vocab_size]\n",
        "\t\t\"\"\"\n",
        "\t\n",
        "\t\t# TODO:\n",
        "\t\t#1) Add the positional embeddings to french sentence embeddings\n",
        "\t\tlocated_french = self.position_fr(self.fr_embedding(encoder_input))\n",
        "\t\t#2) Pass the french sentence embeddings to the encoder\n",
        "\t\tencoded = self.encoder(located_french)\n",
        "\t\t#3) Add positional embeddings to the english sentence embeddings\n",
        "\t\tlocated_english = self.position_en(self.en_embedding(decoder_input))\n",
        "\t\t#4) Pass the english embeddings and output of your encoder, to the decoder\n",
        "\t\tdecoded = self.decoder(located_english, encoded)\n",
        "\t\t#5) Apply dense layer(s) to the decoder out to generate probabilities\n",
        "\t\tprobabilities = self.dense2(decoded)\n",
        "\t\treturn probabilities\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZHgD_rPEMoN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}